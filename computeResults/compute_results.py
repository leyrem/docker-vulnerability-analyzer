import pandas as pd
import altair as alt
import json
import glob
import os
from concurrent.futures import ProcessPoolExecutor, as_completed
import itertools
from utils import process_file, parse_unique_cves_field, extract_severity, get_cve_details

# Paths
DIR_OFFICIAL = '/root/docker-vulnerability-analyzer/out/analysis/official/'
DIR_VERIFIED = '/root/docker-vulnerability-analyzer/out/analysis/verified/'
DIR_SPONSORED = '/root/docker-vulnerability-analyzer/out/analysis/sponsored/'

num_images_analysed = 0

# Load data
df_official = pd.read_csv('/root/thesis_crawler/imagesOfficial.csv')
df_verified = pd.read_csv('/root/thesis_crawler/imagesVerified.csv')
df_sponsored = pd.read_csv('/root/thesis_crawler/imagesSponsored.csv')

SELECTED_NAME = "Official Images" # Oneof Official Images, Verified Images, Sponsored Images or All Images
RECOM_SEVERITIES = False

df_cves_detected_all_scanners = pd.DataFrame()
df_unique_cves = pd.DataFrame()

if SELECTED_NAME == "Official Images":
    df_cves_detected_all_scanners = pd.read_csv('/root/docker-vulnerability-analyzer/computeResults')
elif SELECTED_NAME == "Verified Images":
    directory = DIR_VERIFIED
elif SELECTED_NAME == "Sponsored Images":
    directory = DIR_SPONSORED





# Compute the unique CVEs among all images     
unique_CVEs_all = {}
        
for index, row in df_unique_cves.iterrows():
    detection_rate = row['detection_rate']
    scanner_cve_inf = row['scanner_cve_info']
    scanner_cve_inf_df = parse_unique_cves_field(scanner_cve_inf)
    cve_id = scanner_cve_inf_df['cve_id'].iloc[0]
    
    if cve_id in unique_CVEs_all:
        unique_CVEs_all[cve_id].append(scanner_cve_inf_df)
    else:
        unique_CVEs_all[cve_id] = [scanner_cve_inf_df]
            
# Create DF to store the number of images in which each CVE is present
cves_freq_df = pd.DataFrame(columns=['CVE ID', 'Images Present Count', 'Image Present %'])
    
num_low_vulns = 0
num_medium_vulns = 0
num_high_vulns = 0
num_critical_vulns = 0
num_unassigned_vulns = 0
num_diff_vulns = 0
num_reports_unmatch = 0

i = 1
for key, value in unique_CVEs_all.items():
    perc = (len(value) / num_images_analysed)*100
    single_row = pd.DataFrame([{'CVE ID': key, 'Images Present Count': len(value), 'Image Present %': perc}])
    cves_freq_df = pd.concat([cves_freq_df, single_row], ignore_index=True)

    value_sev_set = set()
            
    print(f"Doing loop {i} out of: {len(unique_CVEs_all)}")
    i += 1
            
            # PARELLISE LOOP
            #with ProcessPoolExecutor() as executor:
                #futures = list(executor.map(extract_severity, itertools.repeat(key), value, itertools.repeat(False)))

                #for future in futures:
                    #value_sev_set.add(future)
        
    for scanner_cve_info_obj_df in value:
        value_sev = extract_severity(key, scanner_cve_info_obj_df, RECOM_SEVERITIES)
        value_sev_set.add(value_sev)
                
    if len(value_sev_set) == 0:
        print("ERROR OCCURRED WHILE ASSESING SEVERITIES, NO VALUE ASSIGNED")
    elif len(value_sev_set) == 1:
        val = list(value_sev_set)[0]
        if val == "LOW":
            num_low_vulns += 1
        elif val == "MEDIUM":
            num_medium_vulns += 1
        elif val == "HIGH":
            num_high_vulns += 1
        elif val == "CRITICAL":
            num_critical_vulns += 1
        elif val == "UNASSIGNED":
            num_unassigned_vulns += 1
        elif val == "DIFFERING":
            num_diff_vulns += 1
    else:
        num_reports_unmatch += 1
        #st.write("DIFFERENT SEVERITIES ASSIGNED FOR THE SAME CVE IN DIFFERENT IMAGE RESULTS")
        
data_output = {
    "images_analysed_type": SELECTED_NAME,
    "number_images_analysed": num_images_analysed,
    "low_vulnerabilities": num_low_vulns,
    "medium_vulnerabilitites": num_medium_vulns,
    "high_vulnerabilities": num_high_vulns,
    "critical_vulnerabilitites": num_critical_vulns,
    "unassigned_vulnerabilities": num_unassigned_vulns,
    "differing_vulnerabilitites": num_diff_vulns,
    "reports_dont_match_vulns": num_reports_unmatch,
}

with open('data_results.json', 'w') as json_file:
    json.dump(data_output, json_file, indent=4)
        
                
cves_freq_df_sorted = cves_freq_df.sort_values(by='Images Present Count', ascending=False)

# Save the DataFrame to a CSV file
cves_freq_df_sorted.to_csv('cves_freq_sorted_df.csv', index=False)