import pandas as pd
import json
import glob
import os
from concurrent.futures import ProcessPoolExecutor
from utils import process_file, process_image, get_metadata
import numpy as np

# Paths
DIR_OFFICIAL = '/root/docker-vulnerability-analyzer/out/analysis/official/'
DIR_VERIFIED = '/root/docker-vulnerability-analyzer/out/analysis/verified/'
DIR_SPONSORED = '/root/docker-vulnerability-analyzer/out/analysis/sponsored/'

num_images_analysed = 0

# Load data
df_official = pd.read_csv('/root/thesis_crawler/imagesOfficial.csv')
df_verified = pd.read_csv('/root/thesis_crawler/imagesVerified.csv')
df_sponsored = pd.read_csv('/root/thesis_crawler/imagesSponsored.csv')

SELECTED_NAME = "Official Images" # Oneof Official Images, Verified Images, Sponsored Images or All Images

directory = ''
if SELECTED_NAME == "Official Images":
    directory = DIR_OFFICIAL
elif SELECTED_NAME == "Verified Images":
    directory = DIR_VERIFIED
elif SELECTED_NAME == "Sponsored Images":
    directory = DIR_SPONSORED

df_cves_detected_all_scanners = pd.DataFrame()
df_unique_cves = pd.DataFrame()

df_images_stats = pd.DataFrame(columns=[
    'Image and Tag Name', 'Number of unique CVEs', 
    'Low CVEs', 'Medium CVEs', 'High CVEs', 'Critical CVEs', 
    'Unassigned CVEs', 'Differing CVEs', 'Number of Pulls',
    'Number of Repo Stars', 'Category', 'SubCategories', 'Size'])

num_cves_list = []

iii = 1
# Load dataframes
if directory == '': # Case ALL IMAGES
    list_dirs = [DIR_OFFICIAL, DIR_VERIFIED, DIR_SPONSORED]
    num_images_analysed = 0
    for d in list_dirs:
        pattern = os.path.join(d, '*')
        file_list = [filename for filename in glob.glob(pattern) if os.path.isfile(filename)]
    
        with ProcessPoolExecutor() as executor:
            results = list(executor.map(process_file, file_list))
            
        # Combine results
        for df1, df2, num, img_name in results:
            num_cves_list.append(num)
            df_cves_detected_all_scanners = pd.concat([df_cves_detected_all_scanners, df1], ignore_index=True)
            df_unique_cves = pd.concat([df_unique_cves, df2], ignore_index=True)
            num_images_analysed += 1
            print(f"Loading data {iii}")
            iii += 1
            
            name_type = ""
            if d == DIR_OFFICIAL:
                name_type = "Official Images"
            elif d == DIR_VERIFIED:
                name_type = "Verified Images"
            elif d == DIR_SPONSORED:
                name_type = "Sponsored Images"
                
            num_unique_cves, final_pkg_list, num_low_vulns, num_medium_vulns, num_high_vulns, num_critical_vulns, num_unassigned_vulns, num_diff_vulns = process_image(df2)
            c, sta, p, sub, siz = get_metadata(img_name, name_type, df_official, df_verified, df_sponsored)
            
            
            single_row = pd.DataFrame([{
                'Image and Tag Name': img_name, 
                'Number of unique CVEs': num_unique_cves, 
                'Low CVEs': num_low_vulns,
                'Medium CVEs': num_medium_vulns,
                'High CVEs': num_high_vulns,
                'Critical CVEs': num_critical_vulns,
                'Unassigned CVEs': num_unassigned_vulns,
                'Differing CVEs': num_diff_vulns,
                'Number of Pulls': p, 
                'Number of Repo Stars': sta,
                'Category': c,
                'SubCategories': sub,
                'Size': siz,
            }])
            df_images_stats = pd.concat([df_images_stats, single_row], ignore_index=True)

else:    
    pattern = os.path.join(directory, '*')
    num_images_analysed = 0
    file_list = [filename for filename in glob.glob(pattern) if os.path.isfile(filename)]
    
    with ProcessPoolExecutor() as executor:
        results = list(executor.map(process_file, file_list))
        
    # Combine results
    for df1, df2, num, img_name in results:
        num_cves_list.append(num)
        df_cves_detected_all_scanners = pd.concat([df_cves_detected_all_scanners, df1], ignore_index=True)
        df_unique_cves = pd.concat([df_unique_cves, df2], ignore_index=True)
        num_images_analysed += 1
        
        num_unique_cves, final_pkg_list, num_low_vulns, num_medium_vulns, num_high_vulns, num_critical_vulns, num_unassigned_vulns, num_diff_vulns = process_image(df2)
        c, sta, p, sub, siz = get_metadata(img_name, SELECTED_NAME, df_official, df_verified, df_sponsored)
        
        single_row = pd.DataFrame([{
            'Image and Tag Name': img_name, 
            'Number of unique CVEs': num_unique_cves, 
            'Low CVEs': num_low_vulns,
            'Medium CVEs': num_medium_vulns,
            'High CVEs': num_high_vulns,
            'Critical CVEs': num_critical_vulns,
            'Unassigned CVEs': num_unassigned_vulns,
            'Differing CVEs': num_diff_vulns,
            'Number of Pulls': p, 
            'Number of Repo Stars': sta,
            'Category': c,
            'SubCategories': sub,
            'Size': siz,
        }])
        df_images_stats = pd.concat([df_images_stats, single_row], ignore_index=True)
        
        print(f"Loading data {iii}")
        iii += 1
        
# Save the DataFrame to a CSV file
name1 = "df_cves_detected_all_scanners_" + SELECTED_NAME + ".csv"
name2 = "df_unique_cves_" + SELECTED_NAME + ".csv"
#df_cves_detected_all_scanners.to_csv(name1, index=False)
#df_unique_cves.to_csv(name2, index=False)

# Convert to numpy array
data_array = np.array(num_cves_list)

# Compute statistics
average_cves_per_image = np.mean(data_array).item()
median_cves_per_image = np.median(data_array).item()
variance_cves_per_image = np.var(data_array, ddof=1).item()  # ddof=1 for sample variance
std_dev_cves_per_image = np.std(data_array, ddof=1).item()  # ddof=1 for sample standard deviation
min_value_cves_per_images = np.min(data_array).item()
max_value_cves_per_image = np.max(data_array).item()
range_value_cves_per_image = max_value_cves_per_image - min_value_cves_per_images

data_output = {
    "executing_script" : "get_dataframes.py",
    "images_analysed_type": SELECTED_NAME,
    "number_images_analysed": num_images_analysed,
    "len_num_cves_list": len(num_cves_list),
    "average_cves_per_image": average_cves_per_image,
    "median_cves_per_image": median_cves_per_image,
    "variance_cves_per_image": variance_cves_per_image,
    "std_dev_cves_per_image": std_dev_cves_per_image,
    "min_value_cves_per_images": min_value_cves_per_images,
    "max_value_cves_per_image": max_value_cves_per_image,
    "range_value_cves_per_image": range_value_cves_per_image,
}

#json_file_name = 'out/general_stats_' + SELECTED_NAME + '.json'
#with open(json_file_name, 'w') as json_file:
    #json.dump(data_output, json_file, indent=4)
    
    
name12 = "df_images_stats_" + SELECTED_NAME + ".csv"
df_images_stats.to_csv(name12, index=False)
