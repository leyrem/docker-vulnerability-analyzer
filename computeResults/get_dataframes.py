import pandas as pd
import json
import glob
import os
from concurrent.futures import ProcessPoolExecutor
from utils import process_file, parse_unique_cves_field

# Paths
DIR_OFFICIAL = '/root/docker-vulnerability-analyzer/out/analysis/official/'
DIR_VERIFIED = '/root/docker-vulnerability-analyzer/out/analysis/verified/'
DIR_SPONSORED = '/root/docker-vulnerability-analyzer/out/analysis/sponsored/'

num_images_analysed = 0

# Load data
df_official = pd.read_csv('/root/thesis_crawler/imagesOfficial.csv')
df_verified = pd.read_csv('/root/thesis_crawler/imagesVerified.csv')
df_sponsored = pd.read_csv('/root/thesis_crawler/imagesSponsored.csv')

SELECTED_NAME = "Verified Images" # Oneof Official Images, Verified Images, Sponsored Images or All Images

directory = ''
if SELECTED_NAME == "Official Images":
    directory = DIR_OFFICIAL
elif SELECTED_NAME == "Verified Images":
    directory = DIR_VERIFIED
elif SELECTED_NAME == "Sponsored Images":
    directory = DIR_SPONSORED

df_cves_detected_all_scanners = pd.DataFrame()
df_unique_cves = pd.DataFrame()

iii = 1
# Load dataframes
if directory == '': # Case ALL IMAGES
    list_dirs = [DIR_OFFICIAL, DIR_VERIFIED, DIR_SPONSORED]
    num_images_analysed = 0
    for d in list_dirs:
        pattern = os.path.join(d, '*')
        file_list = [filename for filename in glob.glob(pattern) if os.path.isfile(filename)]
    
        with ProcessPoolExecutor() as executor:
            results = list(executor.map(process_file, file_list))
            
        # Combine results
        for df1, df2 in results:
            df_cves_detected_all_scanners = pd.concat([df_cves_detected_all_scanners, df1], ignore_index=True)
            df_unique_cves = pd.concat([df_unique_cves, df2], ignore_index=True)
            num_images_analysed += 1
            print(f"Loading data {iii}")
            iii += 1

else:    
    pattern = os.path.join(directory, '*')
    num_images_analysed = 0
    file_list = [filename for filename in glob.glob(pattern) if os.path.isfile(filename)]
    
    with ProcessPoolExecutor() as executor:
        results = list(executor.map(process_file, file_list))
        
    # Combine results
    for df1, df2 in results:
        df_cves_detected_all_scanners = pd.concat([df_cves_detected_all_scanners, df1], ignore_index=True)
        df_unique_cves = pd.concat([df_unique_cves, df2], ignore_index=True)
        num_images_analysed += 1
        print(f"Loading data {iii}")
        iii += 1
        
# Save the DataFrame to a CSV file
name1 = "df_cves_detected_all_scanners_" + SELECTED_NAME + ".csv"
name2 = "df_unique_cves_" + SELECTED_NAME + ".csv"
df_cves_detected_all_scanners.to_csv(name1, index=False)
df_unique_cves.to_csv(name2, index=False)